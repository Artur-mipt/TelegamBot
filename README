В репозитории TelegramBot реализован бот, который парсит страницу на википедии.

<b> Схема работы: </b>

1) Пользователь вводит ссылку на странице и указывает глубину парсинга. Бот обрабатывает
это сообщение, парсит страницу со всеми вложениями в неё (в зависимости от глубины), строит по
полученным данным словари: <слово - частота>, <слово1 - слово2: частота>, <слово2 - слово1: частота>,
где слово2 идет после слово1 в одной из обработанных статей.

2) Далее пользователь может вводить команды для получения интересующих его данных об обработанных
статьях. Список команд и их описания можно узнать, воспользовавшись /help.


<b> Парсинг реализован в директории ParsingPage: </b>

1) BuildingJson - принимает ссылку на статью, проходится
по всем вложениям и вызывает парсинг от них, результат загружает в директорию NotSrcFiles в виде файлов
в формате json.

2) ParseHtml - выделяет в html коде основную часть, в виде текста передаёт её в BuildingModel.

3) BuildingModel - строит по тексту словари.


<b> Обработка команд реализована в директории BaseCommands: </b>

В каждом файле реализована функция, обрабатывающая конкретную команду.


<b> Все файлы, нужные для реализации, но не содержащие код, загружаются и выгружаются локально
из директории NotSrcFiles </b>


<b> Использованные библиотеки: </b>

1) Для выгрузки html кода - urllib.request

2) Для обработки html-кода - bs4.BeautifulSoup и re

3) Для загрузки и выгрузки файлов в формате json - json

4) Для реализации интерфейса бота - python-telegram-bot

5) Для вычисления средней частоты и стандартного отклонения - numpy

6) Для сортировки словаря по значения - operator.itemgetter

7) Для создания облака слов - wordcloud

8) Для отрисовки облака слов и графиков распределения длин и частот - matplotlib.pyplot
